{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_observations = int(10000)  # num of observations in to be created np datasets\n",
    "\n",
    "# feature vector creation 4 features\n",
    "feature0 = np.random.choice([False, True], n_observations)\n",
    "feature1 = np.random.randint(0, 5, n_observations)\n",
    "strings = np.array([b\"a\", b\"b\", b\"c\", b\"d\", b\"e\"])  # strings to match range of feature1\n",
    "feature2 = strings[feature1]\n",
    "feature3 = np.random.randn(n_observations)\n",
    "\n",
    "\n",
    "features_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (feature0, feature1, feature2, feature3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(False, shape=(), dtype=bool)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(b'a', shape=(), dtype=string)\n",
      "tf.Tensor(-0.18806733161890243, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "for f0, f1, f2, f3 in features_dataset.take(1):  # ret one row of feature tuple\n",
    "    print(f0)\n",
    "    print(f1)\n",
    "    print(f2)\n",
    "    print(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\nO\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\n\\x11\\n\\x08feature2\\x12\\x05\\n\\x03\\n\\x01c\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04$\\xb9\\xfc='\n"
     ]
    }
   ],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.train.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def serialize_example(feature0, feature1, feature2, feature3):\n",
    "  \"\"\"\n",
    "  Creates a tf.train.Example message ready to be written to a file.\n",
    "  the 4 features are the previously created 4 feature arrays\n",
    "  \"\"\"\n",
    "  # Create a dictionary mapping the feature name to the tf.train.Example-compatible\n",
    "  # data type.\n",
    "  feature = {\n",
    "      'feature0': _int64_feature(feature0),\n",
    "      'feature1': _int64_feature(feature1),\n",
    "      'feature2': _bytes_feature(feature2),\n",
    "      'feature3': _float_feature(feature3),\n",
    "  }\n",
    "  # Create a Features message using tf.train.Example.\n",
    "  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "  return example_proto.SerializeToString()  # ret tf.train.Example serialized as string\n",
    "\n",
    "\n",
    "serialized_example = serialize_example(False, 4, b\"c\", 0.1234)\n",
    "print(serialized_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features {\n",
       "  feature {\n",
       "    key: \"feature0\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 0\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"feature1\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 4\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"feature2\"\n",
       "    value {\n",
       "      bytes_list {\n",
       "        value: \"c\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"feature3\"\n",
       "    value {\n",
       "      float_list {\n",
       "        value: 0.1234\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets binary or serialized value in original tf.example\n",
    "example_returned = tf.train.Example.FromString(serialized_example)\n",
    "\n",
    "example_returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving and Loading tf.Example bin using tf.Record**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function takes features and serializes them them, then return the serialized\n",
    "# tf.example string\n",
    "def tf_serialize_example(f0,f1,f2,f3):\n",
    "  tf_string = tf.py_function(\n",
    "    serialize_example,\n",
    "    (f0,f1,f2,f3),  # pass these args to the above function.\n",
    "    tf.string)      # the return type is `tf.string`.\n",
    "  return tf.reshape(tf_string, ()) # The result is a scalar\n",
    "\n",
    "serialized_dataset = features_dataset.map(tf_serialize_example)  # map function over entire dataset, to get serialized dataset\n",
    "serialized_dataset\n",
    "\n",
    "# method 1: of getting serialized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FlatMapDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method 2: of getting serialized dataset\n",
    "def generator():\n",
    "  for features in features_dataset:\n",
    "    yield serialize_example(*features)  # yield returns the serialized feature without breaking loop\n",
    "\n",
    "    \n",
    "serialized_dataset = tf.data.Dataset.from_generator(\n",
    "    generator, output_types = tf.string, output_shapes=()\n",
    ")\n",
    "\n",
    "serialized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "TypeError: <tf.Tensor: shape=(), dtype=bool, numpy=False> has type <class 'tensorflow.python.framework.ops.EagerTensor'>, but expected one of: (<class 'int'>,)\nTraceback (most recent call last):\n\n  File \"D:\\Anaconda_3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 244, in __call__\n    ret = func(*args)\n\n  File \"D:\\Anaconda_3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 302, in wrapper\n    return func(*args, **kwargs)\n\n  File \"D:\\Anaconda_3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 827, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"<ipython-input-42-5b7ac67b5a26>\", line 4, in generator\n    yield serialize_example(*features)  # yield returns the serialized feature without breaking loop\n\n  File \"<ipython-input-37-5d88c3e19ce8>\", line 27, in serialize_example\n    'feature0': _int64_feature(feature0),\n\n  File \"<ipython-input-37-5d88c3e19ce8>\", line 16, in _int64_feature\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\n  File \"D:\\Anaconda_3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\", line 553, in init\n    copy.extend(field_value)\n\n  File \"D:\\Anaconda_3\\lib\\site-packages\\google\\protobuf\\internal\\containers.py\", line 282, in extend\n    new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]\n\n  File \"D:\\Anaconda_3\\lib\\site-packages\\google\\protobuf\\internal\\containers.py\", line 282, in <listcomp>\n    new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]\n\n  File \"D:\\Anaconda_3\\lib\\site-packages\\google\\protobuf\\internal\\type_checkers.py\", line 171, in CheckValue\n    raise TypeError(message)\n\nTypeError: <tf.Tensor: shape=(), dtype=bool, numpy=False> has type <class 'tensorflow.python.framework.ops.EagerTensor'>, but expected one of: (<class 'int'>,)\n\n\n\t [[{{node PyFunc}}]] [Op:DatasetToTFRecord]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-28727395573f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFRecordWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserialized_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda_3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\writers.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    112\u001b[0m               \u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_legacy_output_shapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m               dataset_ops.get_legacy_output_types(dataset)))\n\u001b[1;32m--> 114\u001b[1;33m     return gen_experimental_dataset_ops.dataset_to_tf_record(\n\u001b[0m\u001b[0;32m    115\u001b[0m         dataset._variant_tensor, self._filename, self._compression_type)  # pylint: disable=protected-access\n",
      "\u001b[1;32mD:\\Anaconda_3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_experimental_dataset_ops.py\u001b[0m in \u001b[0;36mdataset_to_tf_record\u001b[1;34m(input_dataset, filename, compression_type, name)\u001b[0m\n\u001b[0;32m    979\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda_3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6842\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6843\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6844\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda_3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: TypeError: <tf.Tensor: shape=(), dtype=bool, numpy=False> has type <class 'tensorflow.python.framework.ops.EagerTensor'>, but expected one of: (<class 'int'>,)\nTraceback (most recent call last):\n\n  File \"D:\\Anaconda_3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 244, in __call__\n    ret = func(*args)\n\n  File \"D:\\Anaconda_3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 302, in wrapper\n    return func(*args, **kwargs)\n\n  File \"D:\\Anaconda_3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 827, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"<ipython-input-42-5b7ac67b5a26>\", line 4, in generator\n    yield serialize_example(*features)  # yield returns the serialized feature without breaking loop\n\n  File \"<ipython-input-37-5d88c3e19ce8>\", line 27, in serialize_example\n    'feature0': _int64_feature(feature0),\n\n  File \"<ipython-input-37-5d88c3e19ce8>\", line 16, in _int64_feature\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\n  File \"D:\\Anaconda_3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\", line 553, in init\n    copy.extend(field_value)\n\n  File \"D:\\Anaconda_3\\lib\\site-packages\\google\\protobuf\\internal\\containers.py\", line 282, in extend\n    new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]\n\n  File \"D:\\Anaconda_3\\lib\\site-packages\\google\\protobuf\\internal\\containers.py\", line 282, in <listcomp>\n    new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]\n\n  File \"D:\\Anaconda_3\\lib\\site-packages\\google\\protobuf\\internal\\type_checkers.py\", line 171, in CheckValue\n    raise TypeError(message)\n\nTypeError: <tf.Tensor: shape=(), dtype=bool, numpy=False> has type <class 'tensorflow.python.framework.ops.EagerTensor'>, but expected one of: (<class 'int'>,)\n\n\n\t [[{{node PyFunc}}]] [Op:DatasetToTFRecord]"
     ]
    }
   ],
   "source": [
    "# saves serialized file to disk\n",
    "filename = \"test.tfrecord\"\n",
    "\n",
    "writer = tf.data.experimental.TFRecordWriter(file_name)\n",
    "writer.write(serialized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the tfRecord dataset\n",
    "filenames = [filename]\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
